# whisper-orchard 🍊
Orange Piと使ってないAndroidスマホを文字起こしバックエンドサーバーとして使うSDGsなシステム

## アーキテクチャ
システムはMaster-Worker構成で作ってます。

以下は開発環境
| ノード | 役割 | デバイス | OS / 環境 | 備考 |
|:-----------|:-----------|:-----------|:-----------|:-----------|
| Master Node | ジョブ管理・統合 | Orange Pi 3 LTS | Armbian | 24h稼働可能かつ省電力なSBCを選択しました |
| Worker Node | OpenAI Whisperの実行 | OPPO A3 5G | Android 14 | Dimensity 6300を積んでる | 

## 作ってるシステムの機能
- Master Node (Orange Pi) の機能
  1. ファイルアップロード受付: クライアントから長時間の音声ファイルを受け取る。

  2. VAD分割処理: FFmpeg等を用い、音声を無音区間で分割する（1チャンクあたり30秒〜3分程度）。

  3. ジョブディスパッチ(将来的に実装する予定): 登録されたWorker（Android）のステータスを確認し、空いている端末に分割ファイルを送信する。

  4. 結果の集約: Workerから返却されたテキストデータを時系列順に結合し、最終的な書き起こしファイルを出力する。

- Worker Node (Android App) の機能
  1. HTTPサーバー待機: ポートを開放し、LAN内からのPOSTリクエストを待ち受ける。

  2. 推論実行: 受け取った音声バイナリに対し、whisper.cpp (Base/Smallモデル) を実行してテキスト化する。

  3. Wake Lock制御: 処理中にOSによってスリープ/キルされないよう、明示的にWake Lockを取得する。

  4. JSONレスポンス: 推論結果のテキストと、処理にかかった時間をJSON形式で返却する。
 
## その他APIなどは現在設計中・・・
